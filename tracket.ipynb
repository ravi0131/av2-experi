{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:08:37.800529Z",
     "start_time": "2025-01-03T17:08:37.758521Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import xxhash\n",
    "from shapely.geometry import Polygon\n",
    "from prototype_utils import get_bbox_corners\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    x: float  # center x\n",
    "    y: float  # center y\n",
    "    l: float  # length\n",
    "    w: float  # width\n",
    "    theta: float  # heading angle\n",
    "    id: int\n",
    "    temporal_score: int\n",
    "    frame_id: int\n",
    "    \n",
    "    def __init__(self, x, y, l, w, theta, frame_id):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.l = l\n",
    "        self.w = w\n",
    "        self.theta = theta\n",
    "        attrs = f\"{x:.10f},{y:.10f},{l:.10f},{w:.10f},{theta:.10f}\".encode()\n",
    "        self.id = xxhash.xxh64(attrs).intdigest()\n",
    "        self.temporal_score = 0\n",
    "        self.frame_id = frame_id\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Tracklet:\n",
    "    id: int\n",
    "    boxes: List[BoundingBox]\n",
    "    confidence: float\n",
    "    velocities: List[Tuple[float, float]]\n",
    "    length: int\n",
    "    # backward_score: int = 0 # maybe not needed\n",
    "    # forward_score: int = 0 # maybe not needed\n",
    "\n",
    "    def predict_next_position(self) -> Tuple[float, float]:\n",
    "        assert self.length >= 1\n",
    "        if len(self.boxes) >= 2:\n",
    "            # Constant velocity assumption\n",
    "            last_box = self.boxes[-1]\n",
    "            prev_box = self.boxes[-2]\n",
    "            return (\n",
    "                2 * last_box.x - prev_box.x,\n",
    "                2 * last_box.y - prev_box.y\n",
    "            )\n",
    "        elif len(self.boxes) == 1:\n",
    "            return self.boxes[-1].x, self.boxes[-1].y\n",
    "        return 0.0, 0.0\n",
    "@dataclass\n",
    "class Frame: \n",
    "    detections: List[BoundingBox]\n",
    "    tracklets: List[Tracklet]\n",
    "    \n",
    "    def __init__(self, detections: List[BoundingBox]):\n",
    "        # Tracklets is a list of tracklets, but at time of initialization, it is empty, because it needs to be computed\n",
    "        self.detections = detections\n",
    "        self.tracklets = []\n",
    "\n",
    "import copy        \n",
    "class OnlineTracker:\n",
    "    def __init__(self):\n",
    "        # self.tracklets: List[List[Tracklet]] = []\n",
    "        self.frames: List[Frame] = []\n",
    "        # We store detections in a separate list because ,there might be tracklets that don't match to any detection\n",
    "        # thus the bbox in such tracklets should not be considered while calculating the temporal score later on\n",
    "        # from the scores of both forward and backward tracking\n",
    "        # self.detections: List[List[BoundingBox]] = [] \n",
    "        self.next_id = 0\n",
    "        self.max_distance = 5.0  # 5.0m matching threshold\n",
    "        self.min_confidence = 0.1\n",
    "        self.nms_iou_threshold = 0.1\n",
    "        self.min_tracklet_length = 2  # Minimum length for consistent tracklets\n",
    "        \n",
    "    def update(self, detections_boxes: List[BoundingBox]) -> Frame:\n",
    "        #self.detections.append(detections)\n",
    "        frame = Frame(detections_boxes)\n",
    "        \n",
    "        #For the very first frame\n",
    "        if len(self.frames) == 0:\n",
    "            self.frames.append(frame)\n",
    "            for box_idx, _ in enumerate(detections_boxes):\n",
    "                self._create_tracklet(box_idx)\n",
    "            self.frames[-1].tracklets = [t for t in self.frames[-1].tracklets if t.confidence >= self.min_confidence]\n",
    "            self._apply_nms()\n",
    "            return frame\n",
    "        \n",
    "        tracklets = copy.deepcopy(self.frames[-1].tracklets) # copy previous frame's tracklets\n",
    "        frame.tracklets = tracklets\n",
    "        self.frames.append(frame)\n",
    "        detections = frame.detections\n",
    "        predictions = [tracklet.predict_next_position() for tracklet in tracklets]\n",
    "\n",
    "        # Compute distance matrix\n",
    "        cost_matrix = np.full((len(tracklets), len(detections)), np.inf) # matrix of size num_tracklets x num_detections\n",
    "        for i, pred in enumerate(predictions):\n",
    "            for j, det in enumerate(detections):\n",
    "                dist = np.sqrt((pred[0] - det.x)**2 + (pred[1] - det.y)**2)\n",
    "                cost_matrix[i, j] = dist\n",
    "\n",
    "        # Greedy matching\n",
    "        matches, matched_tracklets, matched_detections = self._greedy_matching(cost_matrix)\n",
    "\n",
    "        # Update matched tracklets\n",
    "        for track_idx, det_idx in matches:\n",
    "            self._update_tracklet(track_idx, det_idx)\n",
    "\n",
    "        # Extend unmatched tracklets\n",
    "        for i in range(len(tracklets)):\n",
    "            if i not in matched_tracklets:\n",
    "                self._extend_tracklet(i)\n",
    "\n",
    "        # Create new tracklets for unmatched detections\n",
    "        for i in range(len(detections)):\n",
    "            if i not in matched_detections:\n",
    "                self._create_tracklet(i)\n",
    "\n",
    "        # Remove low-confidence tracklets\n",
    "        tracklets = [t for t in tracklets if t.confidence >= self.min_confidence]\n",
    "\n",
    "        # Apply NMS\n",
    "        self._apply_nms()\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def _greedy_matching(self, cost_matrix):\n",
    "        \"\"\"\n",
    "        Calculate matches between tracklets and detections using a greedy algorithm.\n",
    "        \n",
    "        Args: \n",
    "            cost_matrix: 2D numpy array of shape (num_tracklets, num_detections) containing pairwise distances\n",
    "            \n",
    "        Returns:\n",
    "            matches: List of tuples (track_idx, det_idx) representing matched tracklets and detections\n",
    "            matched_tracklets: Set of indices of matched tracklets\n",
    "            matched_detections: Set of indices of matched detections\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        matched_tracklets = set()\n",
    "        matched_detections = set()\n",
    "\n",
    "        for track_idx in range(cost_matrix.shape[0]):\n",
    "            detection_distances = cost_matrix[track_idx]\n",
    "            best_match = np.argmin(detection_distances)\n",
    "\n",
    "            if best_match not in matched_detections and detection_distances[best_match] <= self.max_distance:\n",
    "                matches.append((track_idx, best_match))\n",
    "                matched_tracklets.add(track_idx)\n",
    "                matched_detections.add(best_match)\n",
    "\n",
    "        return matches, matched_tracklets, matched_detections\n",
    "\n",
    "    def _update_tracklet(self, tracklet_idx: int, detection_idx: int):\n",
    "        \"\"\"A tracklet is updated if it is matched to a detection in the current frame\"\"\"\n",
    "        tracklet = self.frames[-1].tracklets[tracklet_idx]\n",
    "        detection = self.frames[-1].detections[detection_idx]\n",
    "        w = sum(0.9**i for i in range(1, tracklet.length + 1))\n",
    "        tracklet.confidence = (w * tracklet.confidence + 1.0) / (w + 1.0)\n",
    "        tracklet.velocities.append((detection.x - tracklet.boxes[-1].x, detection.y - tracklet.boxes[-1].y))\n",
    "        tracklet.boxes.append(detection)\n",
    "        tracklet.length += 1\n",
    "        detection.temporal_score = tracklet.length  # Update temporal score\n",
    "\n",
    "    def _extend_tracklet(self, tracklet_idx: int):\n",
    "        \"\"\"we extend a tracklet if it is not matched to any detection in the current frame\n",
    "        Args:\n",
    "            tracklet_idx: index of the tracklet to extend\n",
    "        \"\"\"\n",
    "        tracklet = self.frames[-1].tracklets[tracklet_idx]\n",
    "        x, y = tracklet.predict_next_position()\n",
    "        last_box = tracklet.boxes[-1]\n",
    "        new_box = BoundingBox(x, y, last_box.l, last_box.w, last_box.theta,last_box.frame_id)\n",
    "        tracklet.boxes.append(new_box)\n",
    "        tracklet.confidence *= 0.9\n",
    "        tracklet.length += 1\n",
    "\n",
    "    def _create_tracklet(self, detection_idx: int):\n",
    "        \"\"\"create a new tracket for a detection that is not matched to any existing tracklet\"\"\"\n",
    "        detection = self.frames[-1].detections[detection_idx]\n",
    "        tracklet_to_add = Tracklet(\n",
    "            id=self.next_id,\n",
    "            boxes=[detection],\n",
    "            confidence=0.9,\n",
    "            velocities=[],\n",
    "            length=1\n",
    "        )\n",
    "        self.frames[-1].tracklets.append(tracklet_to_add)\n",
    "        self.next_id += 1\n",
    "        detection.temporal_score = 0 # Unmatched detections have temporal score 0\n",
    "\n",
    "    def _apply_nms(self):\n",
    "        # Convert tracklet boxes to a format suitable for IoU computation\n",
    "        tracklets = self.frames[-1].tracklets\n",
    "        all_boxes = [tracklet.boxes[-1] for tracklet in tracklets]\n",
    "        confidence  = [tracklet.confidence for tracklet in tracklets]\n",
    "        keep = self._nms(all_boxes,confidence, self.nms_iou_threshold)\n",
    "        tracklets = [tracklets[i] for i in keep]\n",
    "\n",
    "    def _nms(self, boxes: List[BoundingBox],confidence_lst: List[float], iou_threshold: float) -> List[int]:\n",
    "        \"\"\"\n",
    "        Apply non-maximum suppression to the given list of boxes.\n",
    "        Args:\n",
    "            boxes: List of BoundingBoxes\n",
    "            iou_threshold: IoU threshold for suppression\n",
    "        Returns:\n",
    "            List of indices to keep\n",
    "        \"\"\"\n",
    "        assert len(boxes) == len(confidence_lst)\n",
    "        if not boxes:\n",
    "            return []\n",
    "\n",
    "        sorted_indices = np.argsort([cval for cval in confidence_lst])[::-1]  # Sort by confidence value of tracklets\n",
    "\n",
    "        keep = []\n",
    "        while sorted_indices.size > 0:\n",
    "            current = sorted_indices[0]\n",
    "            keep.append(current)\n",
    "            remaining = sorted_indices[1:]\n",
    "\n",
    "            current_box = boxes[current]\n",
    "            remaining_boxes = [boxes[i] for i in remaining]\n",
    "\n",
    "            ious = self._compute_iou(current_box, remaining_boxes)\n",
    "            sorted_indices = remaining[ious < iou_threshold]\n",
    "\n",
    "        return keep\n",
    "\n",
    "    # def _compute_ious(self, box1: BoundingBox, boxes: List[BoundingBox]) -> np.ndarray:\n",
    "    #     # Placeholder IoU computation (for BEV)\n",
    "    #     def iou(b1, b2):\n",
    "    #         inter_x = max(0, min(b1.x + b1.l / 2, b2.x + b2.l / 2) - max(b1.x - b1.l / 2, b2.x - b2.l / 2))\n",
    "    #         inter_y = max(0, min(b1.y + b1.w / 2, b2.y + b2.w / 2) - max(b1.y - b1.w / 2, b2.y - b2.w / 2))\n",
    "    #         inter_area = inter_x * inter_y\n",
    "    #         union_area = b1.l * b1.w + b2.l * b2.w - inter_area\n",
    "    #         return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "    #     return np.array([iou(box1, b) for b in boxes])\n",
    "\n",
    "    def _compute_iou(self, box1: BoundingBox, boxes: List[BoundingBox]) -> np.ndarray:\n",
    "        \"\"\"Calculates IoU of the given box with the array of the given boxes.\n",
    "        Note: the areas are passed in rather than calculated here for efficiency. \n",
    "        Calculate once in the caller to avoid duplicate work.\n",
    "        \n",
    "        Args:\n",
    "            box: a polygon (shapely.geometry.Polygon)\n",
    "            boxes: a numpy array of shape (N,), where each member is a shapely.geometry.Polygon\n",
    "        Returns:\n",
    "            a numpy array of shape (N,) containing IoU values\n",
    "        \"\"\"\n",
    "        box1 = get_bbox_corners((box1.x, box1.y, box1.l, box1.w, box1.theta))\n",
    "        boxes = [get_bbox_corners((b.x, b.y, b.l, b.w, b.theta)) for b in boxes]\n",
    "        box1_poly = Polygon(box1)\n",
    "        boxes_poly = [Polygon(b) for b in boxes]\n",
    "        iou_lst = []\n",
    "        for b in boxes_poly:\n",
    "            intersection = box1_poly.intersection(b).area\n",
    "            union = box1_poly.union(b).area\n",
    "            iou = intersection / union if union > 0 else 0\n",
    "            iou_lst.append(iou)\n",
    "        # return np.array(iou_lst, dtype=np.float32)\n",
    "        return np.array(iou_lst)\n",
    "\n",
    "class BidirectionalTracker:\n",
    "    def __init__(self):\n",
    "        self.forward_tracker = OnlineTracker()\n",
    "        self.backward_tracker = OnlineTracker()\n",
    "        self.forward_track_results = []\n",
    "        self.backward_track_results = []\n",
    "        self.temporal_scores = []\n",
    "\n",
    "    def track(self, frame_detections: List[List[BoundingBox]]) -> List[Frame]:\n",
    "        \"\"\"\n",
    "        Perform tracking for a scene (sequence of lidar frames) in both forward and backward directions.\n",
    "        \n",
    "        Args:\n",
    "            frame_detections: List of frames, where each frame is a list of BoundingBoxes\n",
    "        \n",
    "        Returns:\n",
    "            List of frames with tracking results\n",
    "        \"\"\"\n",
    "        forward_track_results, backward_track_results = self.track_sequence(frame_detections)\n",
    "        return self.compute_temporal_scores(forward_track_results, backward_track_results)\n",
    "    \n",
    "    def track_sequence(self, frame_detections: List[List[BoundingBox]]) -> Tuple[List[Frame], List[Frame]]:\n",
    "        \"\"\"\n",
    "        Perform tracking for a scene (sequence of lidar frames) in both forward and backward directions.\n",
    "        \n",
    "        Args:\n",
    "            frame_detections: List of frames, where each frame is a list of BoundingBoxes\n",
    "        \n",
    "        Returns:\n",
    "            forward_track_results: List of frames with forward tracking results\n",
    "            backward_track_results: List of frames with backward tracking results\n",
    "        \"\"\"\n",
    "        forward_track_results = []\n",
    "        for frame in frame_detections:\n",
    "            frame_obj = self.forward_tracker.update(frame)\n",
    "            forward_track_results.append(frame_obj)\n",
    "\n",
    "        backward_track_results = []\n",
    "        for frame in reversed(frame_detections):\n",
    "            frame_obj = self.backward_tracker.update(frame)\n",
    "            backward_track_results.insert(0, frame_obj)\n",
    "\n",
    "        self.forward_track_results = forward_track_results\n",
    "        self.backward_track_results = backward_track_results\n",
    "        \n",
    "        return forward_track_results, backward_track_results\n",
    "    \n",
    "    def compute_temporal_scores(self, forward_track_results: List[Frame], backward_track_results: List[Frame]) -> List[Frame]:\n",
    "        \"\"\"\n",
    "        Compute temporal scores for each bbox in a frame \n",
    "        \"\"\"\n",
    "        assert len(forward_track_results) == len(backward_track_results)\n",
    "        new_frames = []  \n",
    "        for forward_frame, backward_frame in zip(forward_track_results, backward_track_results):\n",
    "            frame1_bboxes = {bbox.id for bbox in forward_frame.detections}\n",
    "            frame2_bboxes = {bbox.id for bbox in backward_frame.detections}\n",
    "            new_bboxes = []\n",
    "            for bbox_id in frame1_bboxes.keys() & frame2_bboxes.keys():\n",
    "                bbox1 = frame1_bboxes[bbox_id]\n",
    "                bbox2 = frame2_bboxes[bbox_id]\n",
    "                \n",
    "                updated_bbox = copy.deepcopy(bbox1)\n",
    "                updated_bbox.temporal_score = max(bbox1.temporal_score, bbox2.temporal_score)\n",
    "                new_bboxes.append(updated_bbox)\n",
    "            \n",
    "            new_frame = Frame(new_bboxes)\n",
    "            new_frames.append(new_frame)\n",
    "        self.temporal_scores = new_frames\n",
    "        return new_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:35.646574Z",
     "start_time": "2025-01-03T17:06:35.044499Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_bounding_boxes(df: pd.DataFrame, frame_id: int) -> List[BoundingBox]:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame of pseudo-labels to a list of BoundingBox objects.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns cx, cy, length, width, angle.\n",
    "\n",
    "    Returns:\n",
    "        List[BoundingBox]: List of bounding box objects for the given frame.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        BoundingBox(\n",
    "            x=row['box_center_x'],\n",
    "            y=row['box_center_y'],\n",
    "            l=row['box_length'],\n",
    "            w=row['box_width'],\n",
    "            theta=row['ry'],\n",
    "            frame_id=frame_id\n",
    "        )\n",
    "        for _, row in df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:35.741167Z",
     "start_time": "2025-01-03T17:06:35.728170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd\n",
      "C:\\Users\\Ravi\\buni\\output-data\\av2\\bbox-estimation\\ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd\n",
      "C:\\Users\\Ravi\\buni\\output-data\\av2\\bbox-estimation\\ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd\\315968335160099000.feather\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "data_dir = os.path.join(home,\"buni\", \"output-data\",\"av2\", \"bbox-estimation\")\n",
    "\n",
    "scene_idx = 0\n",
    "scene_id = os.listdir(data_dir)[scene_idx]\n",
    "\n",
    "scene_path = os.path.join(data_dir, scene_id)\n",
    "\n",
    "print(scene_id)\n",
    "print(scene_path)\n",
    "\n",
    "\n",
    "print(os.path.join(scene_path, os.listdir(scene_path)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:35.772171Z",
     "start_time": "2025-01-03T17:06:35.758170Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_feather(os.path.join(scene_path, os.listdir(scene_path)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to try out tracking on only a single frame. So in this notebook, we only store all frames of a single scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:36.007529Z",
     "start_time": "2025-01-03T17:06:35.790175Z"
    }
   },
   "outputs": [],
   "source": [
    "frame_detections_df = [(pd.read_feather(os.path.join(scene_path, frame_id)), frame_id.split(\".\")[0]) for frame_id in os.listdir(scene_path)]\n",
    "# Convert to frame-level BoundingBox lists\n",
    "# frame_detections is a list of lists. Main list contains a list of detections for each frame.\n",
    "# Each sublist corresponds to a single frame and is a list of bboxes(detections) for that frame\n",
    "# each elem in frame_detectiosn_df => (df, frame_id)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:36.366430Z",
     "start_time": "2025-01-03T17:06:36.041788Z"
    }
   },
   "outputs": [],
   "source": [
    "frame_detections = [convert_to_bounding_boxes(df_frameid[0], df_frameid[1]) for df_frameid in frame_detections_df] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:06:36.413362Z",
     "start_time": "2025-01-03T17:06:36.401373Z"
    }
   },
   "outputs": [],
   "source": [
    "frame0 = frame_detections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:07:42.436708Z",
     "start_time": "2025-01-03T17:07:42.393293Z"
    }
   },
   "outputs": [],
   "source": [
    "tracker0 = OnlineTracker()\n",
    "track_results0 = tracker0.update(frame0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:14:34.448736Z",
     "start_time": "2025-01-03T17:08:41.876416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the tracker\n",
    "tracker = OnlineTracker()\n",
    "\n",
    "# Track across frames\n",
    "track_results = []\n",
    "for frame in frame_detections:\n",
    "    track_results.append(tracker.update(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T17:15:41.960110Z",
     "start_time": "2025-01-03T17:15:41.939101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bounding box IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Check that all bounding boxes in frames have unique ids\n",
    "\n",
    "def are_bounding_box_ids_unique(frames):\n",
    "    ids = set()  # To store unique IDs\n",
    "    for frame in frames:\n",
    "        for bounding_box in frame.detections:\n",
    "            if bounding_box.id in ids:\n",
    "                return False  # Duplicate ID found\n",
    "            ids.add(bounding_box.id)\n",
    "    return True  # All IDs are unique\n",
    "\n",
    "# Example usage\n",
    "if are_bounding_box_ids_unique(track_results):\n",
    "    print(\"All bounding box IDs are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate bounding box IDs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_tracker = OnlineTracker()\n",
    "\n",
    "back_track_results = []\n",
    "for frame in reversed(frame_detections):\n",
    "    back_track_results.append(back_tracker.update(frame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# forward_lst = [bbox.id for bbox in  track_results[1].detections]\n",
    "# backward_lst = [bbox.id for bbox in  back_track_results[155].detections]\n",
    "\n",
    "# NOTE: Check if bboxes in forward and backward tracking have unique ids and are in reverse order of the other\n",
    "idx_lst = np.arange(len(track_results))\n",
    "\n",
    "for idx_forward, idx_backward in zip(idx_lst, idx_lst[::-1]):\n",
    "    forward_lst = [bbox.id for bbox in  track_results[idx_forward].detections]\n",
    "    backward_lst = [bbox.id for bbox in  back_track_results[idx_backward].detections]\n",
    "    for id_forward, id_backward in zip(forward_lst, backward_lst):\n",
    "        if id_forward != id_backward:\n",
    "            print(\"Mismatch found\")\n",
    "            break\n",
    "    # print(f\"Frame {idx_forward} and Frame {idx_backward} match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tracker = BidirectionalTracker()\n",
    "\n",
    "forwad_results, backward_results = two_tracker.track_sequence(frame_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'detections'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtwo_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_temporal_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwad_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 321\u001b[0m, in \u001b[0;36mBidirectionalTracker.compute_temporal_scores\u001b[1;34m(self, forward_track_results, backward_track_results)\u001b[0m\n\u001b[0;32m    318\u001b[0m new_frames \u001b[38;5;241m=\u001b[39m []  \n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m forward_frame, backward_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(forward_track_results, backward_track_results):\n\u001b[1;32m--> 321\u001b[0m     frame1_bboxes \u001b[38;5;241m=\u001b[39m {bbox\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m \u001b[43mforward_track_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetections\u001b[49m}\n\u001b[0;32m    322\u001b[0m     frame2_bboxes \u001b[38;5;241m=\u001b[39m {bbox\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m backward_track_results\u001b[38;5;241m.\u001b[39mdetections}\n\u001b[0;32m    323\u001b[0m     new_bboxes \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'detections'"
     ]
    }
   ],
   "source": [
    "two_tracker.compute_temporal_scores(forwad_results, backward_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "asdict() should be called on dataclass instances",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     11\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(frames_dict, file)\n\u001b[1;32m---> 13\u001b[0m \u001b[43msave_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwad_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward_results.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m save_to_json(backward_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[81], line 7\u001b[0m, in \u001b[0;36msave_to_json\u001b[1;34m(frames, filename)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_json\u001b[39m(frames: List[Frame], filename: \u001b[38;5;28mstr\u001b[39m):   \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert objects to dictionaries\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     frames_dict \u001b[38;5;241m=\u001b[39m [asdict(frame) \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Save to JSON\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "Cell \u001b[1;32mIn[81], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_json\u001b[39m(frames: List[Frame], filename: \u001b[38;5;28mstr\u001b[39m):   \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert objects to dictionaries\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     frames_dict \u001b[38;5;241m=\u001b[39m [\u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Save to JSON\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\Ravi\\anaconda3\\envs\\av2torchv\\lib\\dataclasses.py:1072\u001b[0m, in \u001b[0;36masdict\u001b[1;34m(obj, dict_factory)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the fields of a dataclass instance as a new dictionary mapping\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03mfield names to field values.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03mtuples, lists, and dicts.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dataclass_instance(obj):\n\u001b[1;32m-> 1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masdict() should be called on dataclass instances\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _asdict_inner(obj, dict_factory)\n",
      "\u001b[1;31mTypeError\u001b[0m: asdict() should be called on dataclass instances"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "\n",
    "\n",
    "def save_to_json(frames: List[Frame], filename: str):   \n",
    "    # Convert objects to dictionaries\n",
    "    frames_dict = [asdict(frame) for frame in frames]\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(frames_dict, file)\n",
    "\n",
    "save_to_json(forwad_results, \"forward_results.json\")\n",
    "save_to_json(backward_results, \"backward_results.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av2torchv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
