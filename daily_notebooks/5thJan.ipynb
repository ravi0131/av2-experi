{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this notebook is to check saving and loading Frames object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from tracklet_claude import *\n",
    "\n",
    "def create_dummy_bbox(frame_id: int, x_base: float = 0.0, y_base: float = 0.0) -> BoundingBox:\n",
    "    \"\"\"Create a dummy bounding box with some random variations\"\"\"\n",
    "    return BoundingBox(\n",
    "        x=x_base + np.random.uniform(-2, 2),\n",
    "        y=y_base + np.random.uniform(-2, 2),\n",
    "        l=np.random.uniform(3, 5),\n",
    "        w=np.random.uniform(1.5, 2.5),\n",
    "        theta=np.random.uniform(-np.pi, np.pi),\n",
    "        frame_id=frame_id\n",
    "    )\n",
    "\n",
    "def create_dummy_tracklet(id: int, num_frames: int, start_frame: int) -> Tracklet:\n",
    "    \"\"\"Create a dummy tracklet with consistent motion\"\"\"\n",
    "    x_base = np.random.uniform(-20, 20)\n",
    "    y_base = np.random.uniform(-20, 20)\n",
    "    x_vel = np.random.uniform(-1, 1)\n",
    "    y_vel = np.random.uniform(-1, 1)\n",
    "    \n",
    "    boxes = []\n",
    "    velocities = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        x = x_base + x_vel * i\n",
    "        y = y_base + y_vel * i\n",
    "        box = create_dummy_bbox(start_frame + i, x, y)\n",
    "        boxes.append(box)\n",
    "        if i > 0:\n",
    "            velocities.append((x_vel + np.random.uniform(-0.1, 0.1), \n",
    "                             y_vel + np.random.uniform(-0.1, 0.1)))\n",
    "    \n",
    "    return Tracklet(\n",
    "        id=id,\n",
    "        boxes=boxes,\n",
    "        confidence=np.random.uniform(0.6, 1.0),\n",
    "        velocities=velocities,\n",
    "        length=num_frames\n",
    "    )\n",
    "\n",
    "def create_dummy_frame(frame_id: int, num_detections: int, num_tracklets: int) -> Frame:\n",
    "    \"\"\"Create a dummy frame with random detections and tracklets\"\"\"\n",
    "    detections = [create_dummy_bbox(frame_id) for _ in range(num_detections)]\n",
    "    \n",
    "    # Create tracklets with varying lengths\n",
    "    tracklets = [\n",
    "        create_dummy_tracklet(\n",
    "            id=i,\n",
    "            num_frames=np.random.randint(2, 6),\n",
    "            start_frame=max(0, frame_id - np.random.randint(0, 3))\n",
    "        )\n",
    "        for i in range(num_tracklets)\n",
    "    ]\n",
    "    \n",
    "    frame = Frame(detections)\n",
    "    frame.tracklets = tracklets\n",
    "    return frame\n",
    "\n",
    "def create_dummy_tracking_data(num_frames: int = 5, \n",
    "                             detections_per_frame: int = 3,\n",
    "                             tracklets_per_frame: int = 2) -> Tuple[List[Frame], List[Frame]]:\n",
    "    \"\"\"\n",
    "    Create dummy forward and backward tracking results for testing\n",
    "    \n",
    "    Args:\n",
    "        num_frames: Number of frames to generate\n",
    "        detections_per_frame: Number of detections per frame\n",
    "        tracklets_per_frame: Number of tracklets per frame\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (forward_results, backward_results)\n",
    "    \"\"\"\n",
    "    forward_results = [\n",
    "        create_dummy_frame(i, detections_per_frame, tracklets_per_frame)\n",
    "        for i in range(num_frames)\n",
    "    ]\n",
    "    \n",
    "    backward_results = [\n",
    "        create_dummy_frame(i, detections_per_frame, tracklets_per_frame)\n",
    "        for i in range(num_frames)\n",
    "    ]\n",
    "    \n",
    "    return forward_results, backward_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def serialize_bbox(bbox):\n",
    "    \"\"\"Convert BoundingBox object to dictionary\"\"\"\n",
    "    return {\n",
    "        'x': float(bbox.x),\n",
    "        'y': float(bbox.y),\n",
    "        'l': float(bbox.l),\n",
    "        'w': float(bbox.w),\n",
    "        'theta': float(bbox.theta),\n",
    "        'id': int(bbox.id),\n",
    "        'temporal_score': int(bbox.temporal_score),\n",
    "        'frame_id': int(bbox.frame_id)\n",
    "    }\n",
    "\n",
    "def serialize_tracklet(tracklet):\n",
    "    \"\"\"Convert Tracklet object to dictionary\"\"\"\n",
    "    return {\n",
    "        'id': int(tracklet.id),\n",
    "        'boxes': [serialize_bbox(box) for box in tracklet.boxes],\n",
    "        'confidence': float(tracklet.confidence),\n",
    "        'velocities': [[float(vx), float(vy)] for vx, vy in tracklet.velocities],\n",
    "        'length': int(tracklet.length)\n",
    "    }\n",
    "\n",
    "def serialize_frame(frame):\n",
    "    \"\"\"Convert Frame object to dictionary\"\"\"\n",
    "    return {\n",
    "        'detections': [serialize_bbox(det) for det in frame.detections],\n",
    "        'tracklets': [serialize_tracklet(track) for track in frame.tracklets]\n",
    "    }\n",
    "\n",
    "def save_tracking_results(forward_results, backward_results, save_path_prefix, json=False):\n",
    "    \"\"\"\n",
    "    Save forward and backward tracking results to files.\n",
    "    \n",
    "    Args:\n",
    "        forward_results: List of Frame objects from forward tracking\n",
    "        backward_results: List of Frame objects from backward tracking\n",
    "        save_path_prefix: String prefix for save paths (without extension)\n",
    "    \"\"\"\n",
    "    forward_filepath = os.path.join(save_path_prefix, 'forward_test.pkl')\n",
    "    backward_filepath = os.path.join(save_path_prefix, 'backward_test.pkl')\n",
    "    if json:\n",
    "        # Save as JSON for human readability\n",
    "        forward_data = [serialize_frame(frame) for frame in forward_results]\n",
    "        backward_data = [serialize_frame(frame) for frame in backward_results]\n",
    "        \n",
    "        with open(forward_filepath, 'w') as f:\n",
    "            json.dump(forward_data, f, indent=2)\n",
    "        \n",
    "        with open(backward_filepath, 'w') as f:\n",
    "            json.dump(backward_data, f, indent=2)\n",
    "        \n",
    "    # Also save as pickle for easier loading in Python\n",
    "    with open(forward_filepath, 'wb') as f:\n",
    "        pickle.dump(forward_results, f)\n",
    "        \n",
    "    with open(backward_filepath, 'wb') as f:\n",
    "        pickle.dump(backward_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "forward_results, backward_results = create_dummy_tracking_data()\n",
    "\n",
    "# Save the dummy data using the previously defined save function\n",
    "save_tracking_results(forward_results, backward_results, os.path.join(os.getcwd(), \"saved_tracklets\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 5 frames from forward tracking data\n",
      "First frame has 3 detections and 2 tracklets\n"
     ]
    }
   ],
   "source": [
    "load_path = os.path.join(os.getcwd(), \"saved_tracklets\")\n",
    "# Optional: Load and verify the pickle files\n",
    "with open(os.path.join(load_path,\"forward_test.pkl\"), 'rb') as f:\n",
    "    loaded_forward = pickle.load(f)\n",
    "print(f\"\\nLoaded {len(loaded_forward)} frames from forward tracking data\")\n",
    "print(f\"First frame has {len(loaded_forward[0].detections)} detections and {len(loaded_forward[0].tracklets)} tracklets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tracklet_claude.BoundingBox"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_forward[0].detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.66 7.36]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "forward_dimensions_lst = [(1.2, 3.4), (5.6, 7.8), (9.0, 1.1)]\n",
    "result = np.percentile(forward_dimensions_lst, 95, axis=0)\n",
    "print(result)\n",
    "# Output:\n",
    "# [8.6, 7.2]  # Example output: 95th percentile for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Corner(Enum):\n",
    "    REAR_LEFT = 0\n",
    "    REAR_RIGHT = 1\n",
    "    FRONT_RIGHT = 2\n",
    "    FRONT_LEFT = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corner.REAR_LEFT\n"
     ]
    }
   ],
   "source": [
    "corner_value = 0\n",
    "\n",
    "corner = Corner(corner_value)\n",
    "print(corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting Array Shape: (3, 4, 2)\n",
      "Resulting Array:\n",
      "[[[ 1  2]\n",
      "  [ 3  4]\n",
      "  [ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]\n",
      "  [13 14]\n",
      "  [15 16]]\n",
      "\n",
      " [[17 18]\n",
      "  [19 20]\n",
      "  [21 22]\n",
      "  [23 24]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: List of numpy arrays of shape (4, 2)\n",
    "list_of_arrays = [\n",
    "    np.array([[1, 2], [3, 4], [5, 6], [7, 8]]),\n",
    "    np.array([[9, 10], [11, 12], [13, 14], [15, 16]]),\n",
    "    np.array([[17, 18], [19, 20], [21, 22], [23, 24]])\n",
    "]\n",
    "\n",
    "# Convert the list to a numpy array of shape (N, 4, 2)\n",
    "array = np.stack(list_of_arrays)\n",
    "\n",
    "print(\"Resulting Array Shape:\", array.shape)\n",
    "print(\"Resulting Array:\")\n",
    "print(array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
